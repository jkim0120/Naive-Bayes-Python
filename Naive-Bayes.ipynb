{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive-Bayes Algorithm\n",
    "=====================\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What Is It?\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive-Bayes algorithm is an intuitive approach to making predictions based on prior beliefs or probabilities. Quoting Jason Brownlee, \"it is the supervised learning approach you would come up with if you wanted to model a predictive modeling problem probabilistically\".\n",
    "\n",
    "Let's dive into the mathematics. We start off with a belief or a *prior probability* of event $A$. This is denoted as $P(A)$. Everything seems to be going well until we're hit with some new evidence $X$, which implies something about our belief. As much as we'd like to, we can't simply ignore $X$ and go home. Instead, given evidence $X$, we must calculate a new value for event $A$ called the *posterior probability*. This is denoted as $P(A | X)$. Finally, for the sake of completion, $P(X | A)$ is the probability of observing evidence $X$ for event $A$ and $P(X)$ is the untouched probability of observing evidence $X$.\n",
    "\n",
    "\\begin{align}\n",
    " P( A | X ) = & \\frac{ P(X | A) P(A) } {P(X) } \\\\\\\\[5pt]\n",
    "\\end{align}\n",
    "\n",
    "You're probably wondering what makes this algorithm *naive*. Well, it's due to the underlying assumption that the probability of event $A$ given any evidence $X_n$ is totally independent of each other. This simplifies a lot of things and explains its popularity in many fields.\n",
    "\n",
    "The content of this notebook uses Python to classify whether a patient is diagnosed with diabetes given a set of attributes. The data set is called the \"Pima Indians Diabetes Data Set\" provided by the National Institute of Diabetes and Digestive and Kidney Diseases. The target accuracy to indicate the algorithm's credibility is between 70% - 76%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Acquisition and Formatting\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is given as a `csv` file, which requires parsing and partitioning to form a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from pima-indians-diabetes.data.csv with 768 rows\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "def load_csv(file):\n",
    "    lines = csv.reader(open(file, 'rb'))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset\n",
    "\n",
    "file = \"pima-indians-diabetes.data.csv\"\n",
    "dataset = load_csv(file)\n",
    "print('Loaded data from {0} with {1} rows').format(file, len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split total data (768 rows) into training set (514 rows) and testing set (254 rows)\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "def partition_data(dataset, ratio):\n",
    "    train_size = int(len(dataset) * ratio)\n",
    "    test_set = list(dataset)\n",
    "    train_set = []\n",
    "    \n",
    "    while len(train_set) < train_size:\n",
    "        index = randrange(len(test_set))\n",
    "        train_set.append(test_set.pop(index))\n",
    "        \n",
    "    return [train_set, test_set]\n",
    "\n",
    "train_set, test_set = partition_data(dataset, 0.67)\n",
    "print('Split total data ({0} rows) into training set ({1} rows) and testing set ({2} rows)').format(len(dataset), len(train_set), len(test_set))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
